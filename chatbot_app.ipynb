{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72cf43f7-1d0c-49ed-9c3f-de1ba29c04cb",
   "metadata": {},
   "source": [
    "# LLM application with LangChain and Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4dac14-e5b3-4eaa-bed2-f9c91d50e39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LANGCHAIN API KEY: ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LANGCHAIN API KEY:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1490922e-26cd-45ba-8695-ca1a48772136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "COHERE API KEY: ········\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"COHERE API KEY:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0beda9-172e-413c-8f93-8d3d7f82f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "model = ChatCohere(model=\"command-r-plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32fd7ed8-8346-42e0-8413-62e2297f35e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!', additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '92fe3771-a462-4359-a605-63977822ac07', 'token_count': {'input_tokens': 78, 'output_tokens': 3}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '92fe3771-a462-4359-a605-63977822ac07', 'token_count': {'input_tokens': 78, 'output_tokens': 3}}, id='run-e331bea7-bcf8-4eff-96b2-3524a2ad933a-0', usage_metadata={'input_tokens': 78, 'output_tokens': 3, 'total_tokens': 81})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca43d1-6ac8-4a05-8fe6-872a62b19189",
   "metadata": {},
   "source": [
    "We parse out this response by using a simple output parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ddc2db6-eca1-48ca-9c5a-480777180750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a031c399-62d3-45e2-b734-8796728f3288",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac42b63-ba32-410c-93bc-00bc32d7a2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc90aef-b8c8-42f4-ae3e-be90f59a1e46",
   "metadata": {},
   "source": [
    "A resposta do modelo é do tipo `string` e contem várias informações além da tradução. Podemos \"encadear\" o modelo com \"output parser\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19f1a8e0-26dc-4c8a-b709-42cc27af57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos a cadeia através do operador |\n",
    "\n",
    "chain = model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a93701e-ee7d-4c79-850b-cda99e79decf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c5faf-d0dc-4a5f-8fcb-ceb7df30f723",
   "metadata": {},
   "source": [
    "Vamos criar um `PromptTemplate` com duas variáveis:\n",
    " * `language`: a língua para qual queremos traduzir\n",
    " * `text`: o texto para ser traduzido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3659451a-5366-489c-b7b9-41bc2f505fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following into {language}:\" # criamos system message\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "975d278c-cb45-492f-bf37-128e48cba977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following into italian:'),\n",
       " HumanMessage(content='hi')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
    "\n",
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ab74f4-0bfb-42e3-ba6d-71fe45287b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criamos a cadeia\n",
    "chain = prompt_template | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cd082db-e2af-4339-8ecf-f14bc151d7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao! In che modo posso aiutarti oggi?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chamamos\n",
    "chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb4f79-438f-49d8-95a2-9bbfa572c4f7",
   "metadata": {},
   "source": [
    "## Servimos o app com LangServe\n",
    "\n",
    "Criamos o arquivo `serve.py` que vai criar um servidor para o app. O arquivo contem:\n",
    "\n",
    "    A definição da cadeia que construimos acima\n",
    "    Nosso app de FastAPI \n",
    "    A definição definição de uma rota a partir da qual servir a cadeia, que é feita com `langserve.add_routes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fae924a1-d398-43e5-b1d0-c50fc399476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497d49b-c8ed-4ccb-ac18-ca545e734f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
